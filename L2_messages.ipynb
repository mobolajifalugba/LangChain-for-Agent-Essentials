{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "190a3c14-4a67-4d64-9378-0b9737e4a5f7",
      "metadata": {
        "id": "190a3c14-4a67-4d64-9378-0b9737e4a5f7"
      },
      "source": [
        "# âœ‰ï¸ Messages\n",
        "  <img src=\"./assets/LC_Messages.png\" width=\"500\">\n",
        "\n",
        "Messages are the fundamental unit of context for models in LangChain. They represent the input and output of models, carrying both the content and metadata needed to represent the state of a conversation when interacting with an LLM."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41c566d2-7844-4901-af65-4a6e58817716",
      "metadata": {
        "id": "41c566d2-7844-4901-af65-4a6e58817716"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bf6ad0d-4efd-4066-9a8d-ca8bb0de94ef",
      "metadata": {
        "id": "8bf6ad0d-4efd-4066-9a8d-ca8bb0de94ef"
      },
      "source": [
        "Load and/or check for needed environmental variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fa9fb12-98e3-490d-9ae6-885054c8f117",
      "metadata": {
        "id": "9fa9fb12-98e3-490d-9ae6-885054c8f117",
        "outputId": "337a06b5-1c89-409a-e552-c67a9a6fa5d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY=****eJgA\n",
            "LANGSMITH_API_KEY=****2eed\n",
            "LANGSMITH_TRACING=true\n",
            "LANGSMITH_PROJECT=****ject\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "from env_utils import doublecheck_env\n",
        "\n",
        "# Load environment variables from .env\n",
        "load_dotenv()\n",
        "\n",
        "# Check and print results\n",
        "doublecheck_env(\"example.env\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-core langchain-community langchain-openai langgraph langchain-groq groq python-dotenv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_-CD8IKNqGN-",
        "outputId": "7643c404-d9db-407e-dabe-f1869176d7b8"
      },
      "id": "_-CD8IKNqGN-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain\n",
            "  Downloading langchain-1.0.8-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (0.3.79)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-1.0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-1.0.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting groq\n",
            "  Downloading groq-0.36.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.42)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-1.0.8-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m93.7/93.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.0.7-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m473.0/473.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.0.3-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.5/82.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-1.0.3-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-1.0.1-py3-none-any.whl (17 kB)\n",
            "Downloading groq-0.36.0-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.3/137.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.5-py3-none-any.whl (35 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.3/208.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, ormsgpack, mypy-extensions, marshmallow, typing-inspect, langgraph-sdk, groq, dataclasses-json, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langchain-groq, langgraph-prebuilt, langchain-classic, langgraph, langchain-community, langchain\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.11\n",
            "    Uninstalling langchain-text-splitters-0.3.11:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.11\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.27\n",
            "    Uninstalling langchain-0.3.27:\n",
            "      Successfully uninstalled langchain-0.3.27\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 groq-0.36.0 langchain-1.0.8 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.0.7 langchain-groq-1.0.1 langchain-openai-1.0.3 langchain-text-splitters-1.0.0 langgraph-1.0.3 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.5 langgraph-sdk-0.2.9 marshmallow-3.26.1 mypy-extensions-1.1.0 ormsgpack-1.12.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "Y98r8Sc-quCt"
      },
      "id": "Y98r8Sc-quCt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"openai/gpt-oss-120b\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "EMTb9XQmq5dX"
      },
      "id": "EMTb9XQmq5dX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "579f27b5-a53a-4f24-9480-6af61823d4e6",
      "metadata": {
        "id": "579f27b5-a53a-4f24-9480-6af61823d4e6"
      },
      "source": [
        "## HumanğŸ‘¨â€ğŸ’» and AI ğŸ¤– Messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91ca38b8-7514-4e18-b141-86f77c684ed2",
      "metadata": {
        "id": "91ca38b8-7514-4e18-b141-86f77c684ed2"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "agent = create_agent(\n",
        "    model=llm,\n",
        "    system_prompt=\"You are a full-stack comedian\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e517775-cdac-43ab-a40b-1a9e8deaa666",
      "metadata": {
        "id": "0e517775-cdac-43ab-a40b-1a9e8deaa666"
      },
      "outputs": [],
      "source": [
        "human_msg = HumanMessage(\"Hello, how are you?\")\n",
        "\n",
        "result = agent.invoke({\"messages\": [human_msg]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60bcefc1-53d7-4723-a3dc-d87983be761a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60bcefc1-53d7-4723-a3dc-d87983be761a",
        "outputId": "efc073d9-f632-4a03-accb-738b4168d31a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hey there! Iâ€™m feeling as refreshed as a freshlyâ€‘deployed microservice after a zeroâ€‘downtime rolloutâ€”no bugs, just jokes. Howâ€™s your stack today? ğŸš€ğŸ˜„\n"
          ]
        }
      ],
      "source": [
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61c37ca3-70f7-4f76-8108-94210ba7f5a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61c37ca3-70f7-4f76-8108-94210ba7f5a5",
        "outputId": "884946b6-5b94-4089-924b-f3feccfc4875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.messages.ai.AIMessage'>\n"
          ]
        }
      ],
      "source": [
        "print(type(result[\"messages\"][-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e186f7e-8818-4de4-bebd-4f73cebe5dfb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e186f7e-8818-4de4-bebd-4f73cebe5dfb",
        "outputId": "300edb59-c389-421a-9789-779c2f180263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "human: Hello, how are you?\n",
            "\n",
            "ai: Hey there! Iâ€™m feeling as refreshed as a freshlyâ€‘deployed microservice after a zeroâ€‘downtime rolloutâ€”no bugs, just jokes. Howâ€™s your stack today? ğŸš€ğŸ˜„\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for msg in result[\"messages\"]:\n",
        "    print(f\"{msg.type}: {msg.content}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7f30337-3873-4b0d-aeff-3c418f5dff32",
      "metadata": {
        "id": "f7f30337-3873-4b0d-aeff-3c418f5dff32"
      },
      "source": [
        "### Altenative formats\n",
        "#### Strings\n",
        "There are situations where LangChain can infer the role from the context, and a simple string is enough to create a message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2450c1b-924a-422c-bac3-62b1f03dc25c",
      "metadata": {
        "id": "d2450c1b-924a-422c-bac3-62b1f03dc25c"
      },
      "outputs": [],
      "source": [
        "agent = create_agent(\n",
        "    model=llm,\n",
        "    system_prompt=\"You are a terse sports poet.\",  # This is a SystemMessage under the hood\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf9a9f83-79d4-4abe-b1e3-45ef58d2f51e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf9a9f83-79d4-4abe-b1e3-45ef58d2f51e",
        "outputId": "5ec61d0c-bac9-484c-a431-75a1814554c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diamond hush,  \n",
            "Leather thudsâ€”time arcs.  \n",
            "Pitch whispers, batter answers,  \n",
            "Grass stains the sunrise.  \n",
            "Three outs, a season's sigh.\n"
          ]
        }
      ],
      "source": [
        "result = agent.invoke({\"messages\": \"Tell me about baseball\"})   # This is a HumanMessage under the hood\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc1544d7-3590-42e9-a56b-0dfb34f28505",
      "metadata": {
        "id": "dc1544d7-3590-42e9-a56b-0dfb34f28505"
      },
      "source": [
        "#### Dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91b11e46-9c25-4828-9c6a-29a4594acdaf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91b11e46-9c25-4828-9c6a-29a4594acdaf",
        "outputId": "9d039fe3-5d90-4532-8163-dc900e5dbd4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lightning on trackâ€”  \n",
            "muscles fire, breath held tight,  \n",
            "finish line whispers.\n"
          ]
        }
      ],
      "source": [
        "result = agent.invoke(\n",
        "    {\"messages\": {\"role\": \"user\", \"content\": \"Write a haiku about sprinters\"}}\n",
        ")\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00905cbe-b248-496f-898c-d223cd1fd0d7",
      "metadata": {
        "id": "00905cbe-b248-496f-898c-d223cd1fd0d7"
      },
      "source": [
        "There are multiple roles:\n",
        "```python\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a sports poetry expert who completes haikus that have been started\"},\n",
        "    {\"role\": \"user\", \"content\": \"Write a haiku about sprinters\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Feet don't fail me...\"}\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1b31b4c-00f0-4b37-8152-6f243590df8e",
      "metadata": {
        "id": "c1b31b4c-00f0-4b37-8152-6f243590df8e"
      },
      "source": [
        "## Output Format\n",
        "### messages\n",
        "Let's create a tool so agent will create some tool messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27831c76-be27-4ee8-a24d-cc6d455f4968",
      "metadata": {
        "id": "27831c76-be27-4ee8-a24d-cc6d455f4968"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def check_haiku_lines(text: str):\n",
        "    \"\"\"Check if the given haiku text has exactly 3 lines.\n",
        "\n",
        "    Returns None if it's correct, otherwise an error message.\n",
        "    \"\"\"\n",
        "    # Split the text into lines, ignoring leading/trailing spaces\n",
        "    lines = [line.strip() for line in text.strip().splitlines() if line.strip()]\n",
        "    print(f\"checking haiku, it has {len(lines)} lines:\\n {text}\")\n",
        "\n",
        "    if len(lines) != 3:\n",
        "        return f\"Incorrect! This haiku has {len(lines)} lines. A haiku must have exactly 3 lines.\"\n",
        "    return \"Correct, this haiku has 3 lines.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "879cad42-e41c-4d03-a118-585ff9dcfb83",
      "metadata": {
        "id": "879cad42-e41c-4d03-a118-585ff9dcfb83"
      },
      "outputs": [],
      "source": [
        "agent = create_agent(\n",
        "    model=llm,\n",
        "    tools=[check_haiku_lines],\n",
        "    system_prompt=\"You are a sports poet who only writes Haiku. You always check your work.\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39a70fbb-1d26-411c-aa87-6077bdf21868",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "39a70fbb-1d26-411c-aa87-6077bdf21868",
        "outputId": "148d8804-06a1-4a3f-ff45-ca131ab1b43e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checking haiku, it has 3 lines:\n",
            " Lightning on the field\n",
            "Footsteps echo, hearts race fast\n",
            "Victory whispers\n",
            "checking haiku, it has 3 lines:\n",
            " Grass glistens, cleats strike\n",
            "Crowd roars, the ball arcs high\n",
            "Champions rise anew\n",
            "checking haiku, it has 3 lines:\n",
            " Sweat glistens, ball flies\n",
            "Net ripples, cheers surge like tide\n",
            "Champions breathe triumph\n",
            "checking haiku, it has 3 lines:\n",
            " Morning mist lifts, \n",
            "Runner's breath syncs with sunrise, \n",
            "Finish line glows gold\n",
            "checking haiku, it has 3 lines:\n",
            " Stadium lights flicker\n",
            "Leather spirals through night air\n",
            "Victory hums low\n",
            "checking haiku, it has 3 lines:\n",
            " Thunderous drums rise\n",
            "Athletes sprint, breath in sync\n",
            "Gold glints on the edge\n",
            "checking haiku, it has 3 lines:\n",
            " Echoes on the court\n",
            "Swoosh of net, swift feet in flight\n",
            "Champions chase dawn\n",
            "checking haiku, it has 3 lines:\n",
            " Whistle pierces dusk\n",
            "Players surge, the ball ignites\n",
            "Glory sparks the night\n",
            "checking haiku, it has 3 lines:\n",
            " Leather thuds on grass\n",
            "Crowd erupts, the goal alights\n",
            "Victory breathes deep\n",
            "checking haiku, it has 3 lines:\n",
            " Midfield thunder rolls\n",
            "Boots strike, the net sighs soft\n",
            "Champions rise anew\n",
            "checking haiku, it has 3 lines:\n",
            " Flash of orange fire\n",
            "Runner's stride cuts the sunrise\n",
            "Finish line awaits\n",
            "checking haiku, it has 3 lines:\n",
            " Stadium pulse beats fast\n",
            "Leather arcs, crowd holds its breath\n",
            "Champions taste sunrise\n",
            "checking haiku, it has 3 lines:\n",
            " Echoes of the crowd\n",
            "Sprinting hearts beat like drums\n",
            "Victory whispers\n",
            "checking haiku, it has 3 lines:\n",
            " Ice cracks beneath blades\n",
            "Skaters carve a silent arc\n",
            "Gold glints in cold air\n"
          ]
        }
      ],
      "source": [
        "result = agent.invoke({\"messages\": \"Please write me a poem\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0b3f31f-7247-4d9c-811d-48b041d8eb9e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "c0b3f31f-7247-4d9c-811d-48b041d8eb9e",
        "outputId": "eae2c860-7568-4e26-f6c2-709124bd21ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Swift wind on the track  \\nFeet pound rhythm, hearts alightâ€”  \\nFinish line glows gold'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "result[\"messages\"][-1].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "605faf3d-c76f-499d-abde-6fe0473eea52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "605faf3d-c76f-499d-abde-6fe0473eea52",
        "outputId": "bc6eb124-225e-4bbb-bdd1-28f4eff56bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ],
      "source": [
        "print(len(result[\"messages\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91779142-2d3a-4e9e-9827-69c538e8f911",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91779142-2d3a-4e9e-9827-69c538e8f911",
        "outputId": "0a7b4f0c-51a7-4b61-fcef-1ea78475c1e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Please write me a poem\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  check_haiku_lines (fc_d1aa4cb2-56c6-4e23-880e-d8afa75aef4a)\n",
            " Call ID: fc_d1aa4cb2-56c6-4e23-880e-d8afa75aef4a\n",
            "  Args:\n",
            "    text: Lightning on the field\n",
            "Footsteps echo, hearts race fast\n",
            "Victory whispers\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: check_haiku_lines\n",
            "\n",
            "Correct, this haiku has 3 lines.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  check_haiku_lines (fc_d527b001-d6df-401e-846e-c014b192de1f)\n",
            " Call ID: fc_d527b001-d6df-401e-846e-c014b192de1f\n",
            "  Args:\n",
            "    text: Grass glistens, cleats strike\n",
            "Crowd roars, the ball arcs high\n",
            "Champions rise anew\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: check_haiku_lines\n",
            "\n",
            "Correct, this haiku has 3 lines.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  check_haiku_lines (fc_afcd6c3a-c642-4cf2-832f-ebc4c590812f)\n",
            " Call ID: fc_afcd6c3a-c642-4cf2-832f-ebc4c590812f\n",
            "  Args:\n",
            "    text: Sweat glistens, ball flies\n",
            "Net ripples, cheers surge like tide\n",
            "Champions breathe triumph\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: check_haiku_lines\n",
            "\n",
            "Correct, this haiku has 3 lines.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  check_haiku_lines (fc_c8e2167c-5af6-40cb-b556-72e12e9f109c)\n",
            " Call ID: fc_c8e2167c-5af6-40cb-b556-72e12e9f109c\n",
            "  Args:\n",
            "    text: Morning mist lifts, \n",
            "Runner's breath syncs with sunrise, \n",
            "Finish line glows gold\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: check_haiku_lines\n",
            "\n",
            "Correct, this haiku has 3 lines.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  check_haiku_lines (fc_d4dbff8d-8e23-48f4-a37d-4d739881fa38)\n",
            " Call ID: fc_d4dbff8d-8e23-48f4-a37d-4d739881fa38\n",
            "  Args:\n",
            "    text: Stadium lights flicker\n",
            "Leather spirals through night air\n",
            "Victory hums low\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: check_haiku_lines\n",
            "\n",
            "Correct, this haiku has 3 lines.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  check_haiku_lines (fc_93ffd0d7-ebd0-433b-aefd-99be1ccc5b5b)\n",
            " Call ID: fc_93ffd0d7-ebd0-433b-aefd-99be1ccc5b5b\n",
            "  Args:\n",
            "    text: Thunderous drums rise\n",
            "Athletes sprint, breath in sync\n",
            "Gold glints on the edge\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: check_haiku_lines\n",
            "\n",
            "Correct, this haiku has 3 lines.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  check_haiku_lines (fc_b0efef24-4de9-4ce4-b6e0-7911f95df145)\n",
            " Call ID: fc_b0efef24-4de9-4ce4-b6e0-7911f95df145\n",
            "  Args:\n",
            "    text: Echoes on the court\n",
            "Swoosh of net, swift feet in flight\n",
            "Champions chase dawn\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: check_haiku_lines\n",
            "\n",
            "Correct, this haiku has 3 lines.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  check_haiku_lines (fc_d81eff0f-a00c-42a8-bcf1-5669fa2cbb25)\n",
            " Call ID: fc_d81eff0f-a00c-42a8-bcf1-5669fa2cbb25\n",
            "  Args:\n",
            "    text: Whistle pierces dusk\n",
            "Players surge, the ball ignites\n",
            "Glory sparks the night\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: check_haiku_lines\n",
            "\n",
            "Correct, this haiku has 3 lines.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  check_haiku_lines (fc_4b4fc039-ad74-4f73-a2c5-16305cc2da24)\n",
            " Call ID: fc_4b4fc039-ad74-4f73-a2c5-16305cc2da24\n",
            "  Args:\n",
            "    text: Leather thuds on grass\n",
            "Crowd erupts, the goal alights\n",
            "Victory breathes deep\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: check_haiku_lines\n",
            "\n",
            "Correct, this haiku has 3 lines.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  check_haiku_lines (fc_3972ea97-6841-4a02-a5c7-ed34f4d600f5)\n",
            " Call ID: fc_3972ea97-6841-4a02-a5c7-ed34f4d600f5\n",
            "  Args:\n",
            "    text: Midfield thunder rolls\n",
            "Boots strike, the net sighs soft\n",
            "Champions rise anew\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: check_haiku_lines\n",
            "\n",
            "Correct, this haiku has 3 lines.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  check_haiku_lines (fc_021c00f3-fce5-4a45-9b21-9845f2a1752f)\n",
            " Call ID: fc_021c00f3-fce5-4a45-9b21-9845f2a1752f\n",
            "  Args:\n",
            "    text: Flash of orange fire\n",
            "Runner's stride cuts the sunrise\n",
            "Finish line awaits\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: check_haiku_lines\n",
            "\n",
            "Correct, this haiku has 3 lines.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  check_haiku_lines (fc_ec5132f7-c5c2-4878-ab65-c0eab28cb549)\n",
            " Call ID: fc_ec5132f7-c5c2-4878-ab65-c0eab28cb549\n",
            "  Args:\n",
            "    text: Stadium pulse beats fast\n",
            "Leather arcs, crowd holds its breath\n",
            "Champions taste sunrise\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: check_haiku_lines\n",
            "\n",
            "Correct, this haiku has 3 lines.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  check_haiku_lines (fc_db5e14f4-02cf-4372-8ddd-ecc16a84daea)\n",
            " Call ID: fc_db5e14f4-02cf-4372-8ddd-ecc16a84daea\n",
            "  Args:\n",
            "    text: Echoes of the crowd\n",
            "Sprinting hearts beat like drums\n",
            "Victory whispers\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: check_haiku_lines\n",
            "\n",
            "Correct, this haiku has 3 lines.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  check_haiku_lines (fc_ca75d751-30a0-4e81-bd63-8e64c7615833)\n",
            " Call ID: fc_ca75d751-30a0-4e81-bd63-8e64c7615833\n",
            "  Args:\n",
            "    text: Ice cracks beneath blades\n",
            "Skaters carve a silent arc\n",
            "Gold glints in cold air\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: check_haiku_lines\n",
            "\n",
            "Correct, this haiku has 3 lines.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Swift wind on the track  \n",
            "Feet pound rhythm, hearts alightâ€”  \n",
            "Finish line glows gold\n"
          ]
        }
      ],
      "source": [
        "for i, msg in enumerate(result[\"messages\"]):\n",
        "    msg.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26c704dd-baf5-4afd-a89c-ef3790fe1310",
      "metadata": {
        "id": "26c704dd-baf5-4afd-a89c-ef3790fe1310"
      },
      "source": [
        "### Other useful information\n",
        "Above, the print messages have just been selecting pieces of the information stored in the messages list. Let's dig into all the information that is available!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1afcfa8-a706-403f-8c29-1f441d174908",
      "metadata": {
        "id": "d1afcfa8-a706-403f-8c29-1f441d174908",
        "outputId": "e0207db2-f30c-49a6-9a4f-4a444e3842fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Please write me a poem', additional_kwargs={}, response_metadata={}, id='13b18ae4-f92e-4582-925a-39d7984806a8'),\n",
              "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 555, 'prompt_tokens': 170, 'total_tokens': 725, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CQbI0V3W0uPCDlcnD4GYTydYxCsAJ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--0055426a-ee06-4daa-a36c-4074fa9c1ceb-0', tool_calls=[{'name': 'check_haiku_lines', 'args': {'text': 'Whistle splits cool air\\nStadium hearts drum in time\\nFootsteps chase the dawn'}, 'id': 'call_uOLf0ZxcBTNBT2a77IZJi1jO', 'type': 'tool_call'}], usage_metadata={'input_tokens': 170, 'output_tokens': 555, 'total_tokens': 725, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 512}}),\n",
              "  ToolMessage(content='Correct, this haiku has 3 lines.', name='check_haiku_lines', id='5aff8da9-c8c0-4bed-b8d4-7bf884a8c097', tool_call_id='call_uOLf0ZxcBTNBT2a77IZJi1jO'),\n",
              "  AIMessage(content='Whistle splits cool air\\nStadium hearts drum in time\\nFootsteps chase the dawn', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 231, 'total_tokens': 252, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CQbIATueaDYKiqYDNX5xKHjKGWCr5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--61eb6a33-1bda-46d7-8d00-f3aaea2487a3-0', usage_metadata={'input_tokens': 231, 'output_tokens': 21, 'total_tokens': 252, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64b0568f-41d7-48e3-b69e-f2b8123d941a",
      "metadata": {
        "id": "64b0568f-41d7-48e3-b69e-f2b8123d941a"
      },
      "source": [
        "You can select just the last message, and you can see where the final message is coming from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bacc660-7997-4da7-9d3e-eee4b8119601",
      "metadata": {
        "id": "4bacc660-7997-4da7-9d3e-eee4b8119601",
        "outputId": "a655eb06-4048-4089-d320-1ca1bf32a4ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Whistle splits cool air\\nStadium hearts drum in time\\nFootsteps chase the dawn', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 231, 'total_tokens': 252, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CQbIATueaDYKiqYDNX5xKHjKGWCr5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--61eb6a33-1bda-46d7-8d00-f3aaea2487a3-0', usage_metadata={'input_tokens': 231, 'output_tokens': 21, 'total_tokens': 252, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[\"messages\"][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7254b9e5-f6ac-432e-bf9a-05676f8e4b3b",
      "metadata": {
        "id": "7254b9e5-f6ac-432e-bf9a-05676f8e4b3b",
        "outputId": "bc7c9b9e-76be-4422-fa0f-f15d94b787ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_tokens': 231,\n",
              " 'output_tokens': 21,\n",
              " 'total_tokens': 252,\n",
              " 'input_token_details': {'audio': 0, 'cache_read': 0},\n",
              " 'output_token_details': {'audio': 0, 'reasoning': 0}}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[\"messages\"][-1].usage_metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "523f453e-a425-4df0-88b0-a04e6e7612ee",
      "metadata": {
        "id": "523f453e-a425-4df0-88b0-a04e6e7612ee",
        "outputId": "638264ba-2557-4b06-9355-b481a3874e43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'token_usage': {'completion_tokens': 21,\n",
              "  'prompt_tokens': 231,\n",
              "  'total_tokens': 252,\n",
              "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
              "   'audio_tokens': 0,\n",
              "   'reasoning_tokens': 0,\n",
              "   'rejected_prediction_tokens': 0},\n",
              "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
              " 'model_provider': 'openai',\n",
              " 'model_name': 'gpt-5-2025-08-07',\n",
              " 'system_fingerprint': None,\n",
              " 'id': 'chatcmpl-CQbIATueaDYKiqYDNX5xKHjKGWCr5',\n",
              " 'service_tier': 'default',\n",
              " 'finish_reason': 'stop',\n",
              " 'logprobs': None}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[\"messages\"][-1].response_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cb5d505-a2db-4f64-9346-03af057b3be6",
      "metadata": {
        "id": "3cb5d505-a2db-4f64-9346-03af057b3be6"
      },
      "source": [
        "### Try it on your own!\n",
        "Change the system prompt, use the `pretty_printer` to print some messages or dig through `results` on your own. Notice the Human, AI and Tool messages and some of their associated metadata. Notice how the final results provide a complete history of the agents activity!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f921687f-005c-4727-b041-18bafbfaf1f7",
      "metadata": {
        "id": "f921687f-005c-4727-b041-18bafbfaf1f7"
      },
      "outputs": [],
      "source": [
        "agent = create_agent(\n",
        "    model=\"openai:gpt-5\",\n",
        "    tools=[check_haiku_lines],\n",
        "    system_prompt=\"Your SYSTEM prompt here\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5e27be2-6bf9-4c0e-b466-8f9e483bfe24",
      "metadata": {
        "id": "c5e27be2-6bf9-4c0e-b466-8f9e483bfe24"
      },
      "outputs": [],
      "source": [
        "for i, msg in enumerate(result[\"messages\"]):\n",
        "    msg.pretty_print()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}